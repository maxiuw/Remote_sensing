{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to measure distances \n",
    "the distances are distorted due to curvature of the earth \n",
    "\n",
    "## types of energy we can sense \n",
    "- magnetic filed\n",
    "- electric field\n",
    "## 2 models \n",
    "- waves \n",
    "- particles (photons)\n",
    "E = planck length * speed of light / wave length \n",
    "\n",
    "long wave -> lower energy, harder to measuer, sensor has to be more sensitive and also will get more noise \n",
    "\n",
    "small waves -> higher energy, easier to detect but easier to bump on smt \n",
    "\n",
    "## bodies EM energy \n",
    "\n",
    "- spectral energy \n",
    "- W/m^2*wavelength - a lot of energy as it gets hotter \n",
    "- higher energt more into blue \n",
    "- emitents [0,1] \n",
    "- some of the peaks of energy will be distorted due to some interference \n",
    "- black box model \n",
    "\n",
    "## visability spectrum \n",
    "\n",
    "- UV light - visable by birds and insects \n",
    "- eyes reflect infrared - used for eye tracker \n",
    "- if we want to skip some material we can use \n",
    "    - bandpass filter \n",
    "    - coat the sensor with the material\n",
    "     \n",
    "## why we dont wanna perfect step signal of the color \n",
    "- the color regions overlap \n",
    "- we do not percive 'perfect blue' or 'perfect green'\n",
    "\n",
    "- for light: Yellow (R+G), Cyan = (B+G) ,Magenda = (R+B)\n",
    "- the more 'blue' we add to we see more red/violet \n",
    "\n",
    "## particles \n",
    "\n",
    "- when we multuply recieved signal by the function of 'particles' we will recieve the ammount of what particles are there e.g. on the other planet \n",
    "\n",
    "## shadow zone and recursion zone\n",
    "- important to understnd while looking at the atmosphere \n",
    "\n",
    "## libraries \n",
    "- measuring vegetation - e.g. how many % of healthy plants we have \n",
    "- a lot of chlorophila - red/green\n",
    "- reflect a lot of infrared \n",
    "\n",
    "## NDVI\n",
    "- normalized difference vegetation index \n",
    "- diff between mirrored infrader and red signal - big diff for healthy vegetatiion\n",
    "- divide by the sum of inf red and red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - feeding multilayer gausian distribution !!! check it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. measure vegetation\n",
    "#### 1. Obtain data \n",
    "#### 2. Visualize the data\n",
    "#### 3. Segment the data \n",
    "#### 4. Find object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lidar - energy in the phase of laser beam is heating the the object \n",
    "and then reflecting the light\n",
    "- usually data in the form of peaks \n",
    "- intensity of the laser \n",
    "- National agriculture data, they have infrared data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data \n",
    "- elevation data (close to 1m as we can get, more accurate the better)\n",
    "- RGB NIR data (napi 1m)\n",
    "- shape that on the map (vector data)\n",
    "\n",
    "### Websites\n",
    "\n",
    "- open topography \n",
    "- usgs earth exploer \n",
    "- https://viewer.nationalmap.gov/basic/\n",
    "\n",
    "Lidar data is big but really high resolution (even in the resolution of inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for jpeg2000 we sometimes have to change it for tip\n",
    "np_ds = rio.open('oxford.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(26916)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_ds.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds.af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np_ds.read(out_shape = (4,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show as ds_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_show(np_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9adfb0add14183bed62e2858840549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc05d2e4bd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faster, not rendering \n",
    "plt.figure('napi-prev')\n",
    "# we have to show just 3 bands \n",
    "plt.imshow(im.transpose(1,2,0)[:,:,(0,1,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetReader' object has no attribute 'affine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ef285230e31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transform.affine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscale_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscale_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmap_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmap_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetReader' object has no attribute 'affine'"
     ]
    }
   ],
   "source": [
    "# transform.affine\n",
    "scale_x = np_ds.affine.a\n",
    "scale_y = np_ds.affine.e\n",
    "map_x = np_ds.affine.c\n",
    "map_y = np_ds.affine.f\n",
    "# print scale \n",
    "# print position - map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['end'](img/endlesson1.png)\n",
    "!['end2'](img/endlesson2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure('map-pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamic range of and eye\n",
    "!['week4'](img/week4.png)\n",
    "!['week](img/week44.png)\n",
    "\n",
    "- we are more sensitive for the values in particular range \n",
    "- it is depending on the e.g. brightness/darkness of the room/place where we are\n",
    "- we adjust the range which we can see by pupile dilegts ( rozszerzanie sie soczewki)\n",
    "- in AI we also do not store all memory, we are more tend to guess - we approximate y' to y gamma,\n",
    "- y - energy values \n",
    "!['week](img/week41.png)\n",
    "- 255 e.g. is gonna be the values of gamma which we sense and picked up \n",
    "- sometimes we have to go to the metadata file to actually know what is the data - on the image the y^gamma approximation is being used\n",
    "!['week](img/week42.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast and brightness\n",
    "\n",
    "gain and bias\n",
    "\n",
    "- we have a space where we can see the colors \n",
    "- this is the are where we see but it is not being particularly correct, it is distorted by gammma transformation \n",
    "- due to the not evenly space , we cannot see evenly well in different colors/spaces\n",
    "- we have some areas \n",
    "\n",
    "HDR \n",
    "!['week](img/week45.png)\n",
    "- take many images and then combine them together \n",
    "- as human beings, we can see all details looking at the sun,\n",
    "- but when taking phot with camra we cannnot do this so welll\n",
    "- we analyze it in our eyes and also our brain \n",
    "- high special resolution \n",
    "- 16 bits -> 0 - 65535 -> better precision \n",
    "- but when representinf floating point numbers, they are still not nonlinear,\n",
    "- the numbers in 16 bits are scaled int - values are from 0 - 1 and then they are devided by 65535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ColorInterp.red: 3>,\n",
       " <ColorInterp.green: 4>,\n",
       " <ColorInterp.blue: 5>,\n",
       " <ColorInterp.alpha: 6>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_ds.colorinterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'uint8',\n",
       " 'nodata': None,\n",
       " 'width': 9910,\n",
       " 'height': 12450,\n",
       " 'count': 4,\n",
       " 'crs': CRS.from_epsg(26916),\n",
       " 'transform': Affine(0.6, 0.0, 687720.0,\n",
       "        0.0, -0.6, 4381818.0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype unisgnt int 8bits \n",
    "np_ds.meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//10 # int division "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = im.astype(np.int)\n",
    "ndvi = (inf[3]-inf[2])/(inf[3]+inf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191892bb636b4757b6fda3641ddd2feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc09e8e8610>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure('ndvi')\n",
    "plt.imshow(ndvi,vmin=0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also look at outside the image \n",
    "im2 = np_ds.read(out_shape = (4,512,512), window = ((-100,100),(5000,6000)),boundless = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc689d7ac7fc46be972b057efdb8d355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (4, 512, 512) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2e5f6b22664a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'window'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maciek/yes/envs/cse620b/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2715\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maciek/yes/envs/cse620b/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maciek/yes/envs/cse620b/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/maciek/yes/envs/cse620b/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    705\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 706\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (4, 512, 512) for image data"
     ]
    }
   ],
   "source": [
    "plt.figure('window')\n",
    "plt.imshow(im2,vmin=0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np_ds.window_bounds([(-100,900),(5000,6000)])\n",
    "# range of lattitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np_ds.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recognition on the image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['week](img/week47.png)\n",
    "- image has bands / channels (e.g. RGB, infrared),\n",
    "- 3D arrays - tensors \n",
    "- columns - spacial locations \n",
    "- channels - attributes of the lacation ('features') \n",
    "- but how to recognize whethere or no a group of attributes is a car/building ect.\n",
    "- we can see if its building but also e.g. what is its hight,\n",
    "- classification problem - recognition, regression problem - measurements\n",
    "- we have a big image, we slide through the image \n",
    "\n",
    "We can try to do it in many ways in all the channels at the same time:\n",
    "- window operation (neighbors)\n",
    "- point operation \n",
    "- we can treat it as a R^C dimensional space but kinda consider it as one point,\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "- e.g. presegmentation, separating on the bigger pieces, bigger than a pixel but smaller than the object we are looking for \n",
    "- clustering based on the channels \n",
    "- e.g. watershed, superpixels, \n",
    "\n",
    "- pixel4D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
