{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exacute module -x startcode\n",
    "![omg](img/week61.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command program interface in __main__.py\n",
    "\n",
    "- one of the biggest challengest is keeping the track of diff configurations of hyper par and layers\n",
    "\n",
    "- 1st would be (deeplab, unet, ... ) already existing project\n",
    "- understanding what existing arch are doing\n",
    "\n",
    "\n",
    "- config.py containing dictionary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-3b9a94b5c2c8>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-3b9a94b5c2c8>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    Config.SLUG =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import startcode  # folder with __init, main and cofig in it\n",
    "import os\n",
    "class Config:\n",
    "    SLUG  = 'default'\n",
    "    DEVICE = 'CPU'\n",
    "    # data\n",
    "    # shortcut to the folder withh data, as if it is located together with the source code\n",
    "    # crating simulink - link to thhat folder \n",
    "    SOURCES_ROOT = os.path.dirname(startcode.__file__)\n",
    "    DATA_ROOT =  os.path.join(SOURCES_ROOT,'--','data') # file where data is, creating the link by '--'\n",
    "\n",
    "\n",
    "    # each dictionary, different configuration, running h params from dictionaries\n",
    "    OPTIONS = dict(\n",
    "                default=dict(\n",
    "                n = 0.001,\n",
    "                arch = 'deeplab'\n",
    "                ))\n",
    "    \n",
    "    # different options for different datasets \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "PREFIX = '_sc_'\n",
    "if 'sc.Slug' in os.environ:\n",
    "    Config.SLUG = default\n",
    "    \n",
    "    \n",
    "if torch.cuda_isavailable:\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-9-cc62351fd043>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-cc62351fd043>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    p.add_argument('--device',type = str,choices = ['gpu','cpu'],default = 'cuda' if torch.cuda_is_available() else 'cpu',help = 'select set of option', default = Config.SLUG)\u001b[0m\n\u001b[0m                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "# __MAIN__\n",
    "# from startercode.cofig import Config \n",
    "\n",
    "# adding more variables, we call program with other docs\n",
    "\n",
    "import argparse\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except ModuleNotFoundError:\n",
    "    print('modul not found, install torch') \n",
    "    # if somebody is using it on different machine,version of torch may be incompatible\n",
    "    # with his machine \n",
    "    raise\n",
    "\n",
    "p = argparse.ArgumentParser()\n",
    "\n",
    "# while calling function, expecting another variable\n",
    "# p.add_argument('--slug',type = str,help = 'select set of option', default = Config.SLUG)\n",
    "\n",
    "# using it on the web server \n",
    "p.add_argument('--device',type = str,choices = ['gpu','cpu'],default = 'cuda' if torch.cuda_is_available() else 'cpu',help = 'select set of option', default = Config.SLUG)\n",
    "\n",
    "# WE CANNOT ADD SUBPARSER TWICE \n",
    "\n",
    "# prepare data \n",
    "\n",
    "# general action \n",
    "\n",
    "# subactions sub parsers\n",
    "sp = p.add_subparsers(title='Actions',description = 'Choose an action')\n",
    "\n",
    "prepare = sp.add_parser('prepare',help = 'inster data to be used for training and validation')\n",
    "prepare.set_defaults(action='prepare') # setting default response\n",
    "\n",
    "\n",
    "train = sp.add_parser('train',help='start trainnig loop')\n",
    "train.set_defaults(action='train') # setting default response\n",
    "train.add_argument('epoch',type=int, default = 100, help ='numer of epochs to train')\n",
    "\n",
    "evaluate = sp.add_parser('eval',help = 'evaluate predictions')\n",
    "evaluate.set_defaults(action='eval') # setting default response\n",
    "\n",
    "test = sp.add_parser('test',help = 'test your model on data ')\n",
    "test.set_defaults(action='test') # setting default response\n",
    "add_argument('input',type=str,help='filename to process')\n",
    "\n",
    "\n",
    "\n",
    "args = p.parse_args()\n",
    "\n",
    "Config.SLUG = args.slug\n",
    "Config.DEVICE = args.device\n",
    "\n",
    "if args.action == 'prepare':\n",
    "    print('prepare data')\n",
    "\n",
    "if args.action == 'train':\n",
    "    print('train data'+st)\n",
    "    \n",
    "    if Config.DEVICE == 'cpu':\n",
    "        print('training on cpu')\n",
    "    \n",
    "'''\n",
    "...\n",
    "'''\n",
    "args = p.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "# using pillow instead of cv2 , or  rasterio for geospecial data\n",
    "# cv2 can break due to DLL issuea, pil images and scikit images\n",
    "# we want the array to be a set of small images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![omg](img/week65_datasetpy.png)\n",
    "![omg](img/week62.png)\n",
    "![omg](img/week63.png)\n",
    "![omg](img/week64.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ln -s ~path  # this adds the foldder to the directory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while downloading data always makes sure that we know what we are doing,\n",
    "- see what e.g. in competition is evaluated\n",
    "- see what a model, can be e.g. pytorch data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in dataset.py\n",
    "# adding calss\n",
    "\n",
    "class LabelData:\n",
    "    def __init__(self,index,name,color):\n",
    "        self.index = index\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "# to class MyDataset:\n",
    "labels = {LabelData(1,'car','blue')} \n",
    "\n",
    "# we add dictionary with labels \n",
    "class MyDataset(Dataset):\n",
    "    LABELS = _LABELS\n",
    "    LABAL_INDEX = {label,number:index for index in ...}\n",
    "\n",
    "# alt+shift+insert, being able to operate on many lines at the same time \n",
    "\n",
    "    @staticmethod\n",
    "    def prepare()\n",
    "        train_filename = Train_LABELS_PATH\n",
    "        ds = fiona.open(train_filename)\n",
    "        data = []\n",
    "        for records in tq.tqdm(ds,data = 'Extracting data'): # adding progress bar \n",
    "            geometry = records['geometry'] # maybe not necessary \n",
    "            fields = records['prooerty']\n",
    "            # boudries in image coordinates \n",
    "            left,top,right,bottom = zip(*[[tin(c) for c in x.split(,)]for x in df['bounds_inrecords']])\n",
    "            properites.update(left = left,right=right...)\n",
    "            data.append(properties)\n",
    "        df = pd.DataFrame.from_records(data)\n",
    "        df.to_csv(MyDataaset.TRAIN_CSV_FILE)\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can test the data beofre creating the whole function to treat data \n",
    "import rasterio as rio\n",
    "import fiona\n",
    "import os \n",
    "\n",
    "df = fiona.open(os.path.join(config))\n",
    "from congig import OPtions\n",
    "\n",
    "os.path.join(Config.Data_ROOT)\n",
    "\n",
    "# if we have many big images which we have to loop over \n",
    "# libraryy: tqdm for looping over data \n",
    "# lis\n",
    "\n",
    "# getting image boundries\n",
    "left,top,right,bottom = zip(*[[tin(c) for c in x.split(,)]for x in df['bounds_inrecords']])\n",
    "\n",
    "# THERE IS a lot of path modification using sys and os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(sefl,index):\n",
    "    rec = self.df.iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How DL works\n",
    "\n",
    "- image \n",
    "- multiply image by weights \n",
    "- add some bias \n",
    "- at the end we get a new image with ne\n",
    "- differen set of weights for diff channels \n",
    "- we pass \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
